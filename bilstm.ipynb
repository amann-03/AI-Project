{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpZBzPEDhdUb",
        "outputId": "9f24c1db-83ff-4f40-b5c8-fde4b8d18c59"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.layers import TimeDistributed, Dense, LSTM, Embedding, Dropout, Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "import pickle\n",
        "\n",
        "np.set_printoptions(threshold=np.inf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVL2B26bh2P5"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"keywords_output.csv\", names = [\"paragraphs\", \"label\"],on_bad_lines='skip')\n",
        "df['paragraphs'] = df['paragraphs'].astype(str)\n",
        "df['label'] = df['label'].astype(str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqfWgzD-iuBQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "vectorizer = TextVectorization(\n",
        "    max_tokens=100000,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=512,\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        ")\n",
        "\n",
        "\n",
        "vectorizer.adapt(df[\"paragraphs\"])\n",
        "vocab = {token:  index for token, index in enumerate(vectorizer.get_vocabulary())}\n",
        "encoded_sequences = vectorizer(df[\"paragraphs\"]).numpy()\n",
        "\n",
        "sentence_column = []\n",
        "keyword_column = []\n",
        "\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    new_keywords = []\n",
        "    sentence = row[\"paragraphs\"]\n",
        "    keywords = row[\"label\"]\n",
        "    tokens = sentence.split()\n",
        "    for token in tokens:\n",
        "        if token in keywords:\n",
        "            if not any(char.isdigit() for char in token):\n",
        "                new_keywords.append(1)\n",
        "        else:\n",
        "            new_keywords.append(0)\n",
        "    if sum(new_keywords) != 0:\n",
        "        sentence_column.append(sentence)\n",
        "        keyword_column.append(new_keywords)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8M5YCgViv3v"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "vectorizer.adapt(sentence_column)\n",
        "X = vectorizer(sentence_column).numpy()\n",
        "X = pad_sequences(X, padding = \"post\", truncating = \"post\", maxlen = 512, value = 0)\n",
        "y = pad_sequences(keyword_column, padding = \"post\", truncating = \"post\", maxlen = 512, value = 0)\n",
        "y = [to_categorical(i, num_classes = 2) for i in y]\n",
        "embeddings_index = {}\n",
        "f = open('embeddings.txt','r')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype = \"float32\")\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPdNDRv2iyB8"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "word_index = vectorizer.get_vocabulary()\n",
        "\n",
        "\n",
        "ed = 100\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, ed))\n",
        "\n",
        "\n",
        "for word, i in enumerate(word_index):\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "0Muwv3mki0NG",
        "outputId": "d7e58fa9-b837-480e-cc83-1767551d2dfb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1, 100, weights = [embedding_matrix]))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences = True, recurrent_dropout = 0.1)))\n",
        "model.add(TimeDistributed(Dense(2, activation = \"softmax\")))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "history = model.fit(X_train, np.array(y_train), batch_size = 64, epochs = 5, validation_split = 0.1)\n",
        "model_json = model.to_json()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test)\n",
        "yhat_classes = np.argmax(predictions, axis=2)\n",
        "testy_inverse = label_encoder.inverse_transform(y_test)\n",
        "\n",
        "# Calculate precision and recall\n",
        "precision = precision_score(testy_inverse.ravel(), yhat_classes.ravel())\n",
        "recall = recall_score(testy_inverse.ravel(), yhat_classes.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "id": "mxhXSmmHLUk5",
        "outputId": "23d27834-7551-4cde-ea24-55e5770b6099"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_test = np.array(y_test)\n",
        "evaluation_results = model.evaluate(X_test, y_test, batch_size=32)\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "loss, accuracy = evaluation_results\n",
        "\n",
        "print(f\"Test loss: {loss:.4f}\")\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1c_9ACsjpgz8"
      },
      "outputs": [],
      "source": [
        "example_sentence = \"Its a very similar sort of thing You end up integrating u12 It leads to the integral of u12 du Is everybody seeing where this However there is a slightly better method So recommended method And I call this method advanced guessing What advanced guessing means is that youve done enough of these problems that you can see two steps ahead And you know whats going to happen So the advanced guessing leads you to believe that here you had a power 12 here you have the differential of the thing So its going to work out somehow And the advanced guessing allows you to guess that the answer should be something like this 1 x212 So this is your advanced guess And now you just differentiate it and see whether it works Well here it is Its 12 1 x212 2x thats the chain rule here Which sure enough gives you x over square root of 1 x2 So were done And so the answer is square root of 1 x2 c Let me illustrate this further with another example I strongly recommend that you do this but you have to get used to it So heres another example e6x dx My advanced guess is e6x And if I check when I differentiate it I get 6e6x Thats the derivative And so I know that the answer so now I know what the answer is Its 16 e6x c Now OK you could its also OK but slow to use a substitution to use u 6x Then youre going to get du 6dx dot dot dot Its going to work its just a waste of time Well Im going to give you a couple more examples So how about this one x ex2 dx Whats the guess Anybody have a guess Well you could also correct So I dont want you to bother yeah go ahead STUDENT INAUDIBLE PROFESSOR Yeah so youre already one step ahead of me\"\n",
        "\n",
        "\n",
        "encoded_example = vectorizer([example_sentence]).numpy()\n",
        "\n",
        "padded_example = pad_sequences(encoded_example, maxlen=512, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "\n",
        "predictions = model.predict(padded_example)\n",
        "predictions = predictions.squeeze()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPlG1gMvofnK",
        "outputId": "cc82ba60-3e59-487f-e504-e7c8a2a69959"
      },
      "outputs": [],
      "source": [
        "inverse_vocab = {token:  index for token, index in enumerate(vectorizer.get_vocabulary())}\n",
        "sorted_indices = np.argsort(predictions[:, 0])[::-1]\n",
        "\n",
        "\n",
        "top_5_indices = sorted_indices[:5]\n",
        "\n",
        "tokens_found = [vocab.get(idx, 'UNKNOWN') for idx in top_5_indices]\n",
        "\n",
        "print(\"Tokens found:\", tokens_found)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
